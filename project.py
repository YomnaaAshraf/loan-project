# -*- coding: utf-8 -*-
"""PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P_yMYonisWLLETXlMzzMEvIKM9f4tOON
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import svm
# %matplotlib inline
from scipy.stats import mstats
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.ensemble import GradientBoostingClassifier
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt

"""# Data Cleaning

"""

df=pd.read_csv("/content/train_u6lujuX_CVtuZ9i.csv")
df

df.info()

df.isnull().sum()

df.head()

df.Gender.fillna(df.Gender.mode()[0],inplace = True)

df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)

df['Married'].fillna(df['Married'].mode()[0], inplace=True)

df.Dependents.value_counts()

df["Dependents"].replace('3+','3',inplace=True)

df.Dependents.value_counts()

df.LoanAmount.fillna(df.LoanAmount.median(),inplace = True)

df.Loan_Amount_Term.fillna(df.Loan_Amount_Term.median(),inplace = True)

df.Credit_History.fillna(df.Credit_History.median(),inplace = True)

df['Dependents'] = pd.to_numeric(df['Dependents'], errors='coerce')
df['Dependents'].fillna(df['Dependents'].median(), inplace=True)

print(df.dtypes)

df.isnull().sum()

df.drop_duplicates()

df.duplicated().sum()

df.boxplot(column=['ApplicantIncome'])
plt.show()

df.boxplot(column=['CoapplicantIncome'])
plt.show()

df.boxplot(column=['LoanAmount'])
plt.show()

df.boxplot(column=['Loan_Amount_Term'])
plt.show()

df.boxplot(column=['Credit_History'])
plt.show()

df["ApplicantIncome"].describe()

columns_to_handle = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']

# Apply Winsorization to handle outliers for each column
for column in columns_to_handle:
    win_data = mstats.winsorize(df[column], limits=[0.09, 0.09])
    df[column] = win_data

# Print the updated DataFrame
print(df.head())

df.boxplot(column=['ApplicantIncome'])
plt.show()

df.boxplot(column=['CoapplicantIncome'])
plt.show()

df.boxplot(column=['LoanAmount'])
plt.show()

df.boxplot(column=['Loan_Amount_Term'])
plt.show()

df.boxplot(column=['Credit_History'])
plt.show()

"""# Exploratory Data Analysis(EDA)

### data description
"""

df.info()

df.describe()

df['Self_Employed'].value_counts()

"""### Data Visualization"""

plt.hist(data=df,x='Credit_History', bins=20, edgecolor='black')
plt.xlabel('Credit_History')
plt.ylabel('credithistory_counts')
plt.title('Distribution of Credit History')
plt.show()

plt.hist(data=df,x='Loan_Status', bins=20, edgecolor='black')
plt.xlabel('Loan Status')
plt.ylabel('Count')
plt.title('Distribution of Loan Amounts')
plt.show()

df['Property_Area'].value_counts()
plt.hist(data=df,x='Property_Area', bins=5, edgecolor='black')
plt.xlabel('Property Area')
plt.ylabel('Frequency')
plt.title('Distribution of Property Area')
plt.show()

plt.hist(data=df,x='LoanAmount', bins=5, edgecolor='black')
plt.xlabel('Loan Amount')
plt.ylabel('Frequency')
plt.title('Distribution of Loan Amounts')
plt.show()

plt.hist(data=df,x='Loan_Amount_Term', bins=10, edgecolor='black')
plt.xlabel('Loan Term')
plt.ylabel('Frequency')
plt.title('Distribution of Loan Terms')
plt.show()

plt.hist(data=df,x='ApplicantIncome', bins=10, edgecolor='black')
plt.xlabel('Applicant Income')
plt.ylabel('Frequency')
plt.title('Distribution of Applicant Incomes')
plt.show()

plt.hist(data=df,x='CoapplicantIncome', bins=10, edgecolor='black')
plt.xlabel('Co-applicant Income')
plt.ylabel('Amount')
plt.title('Distribution of Co-applicant Incomes')
plt.show()

plt.scatter(data = df, x = 'ApplicantIncome', y = 'LoanAmount');
plt.xlabel('Applicant Income')
plt.ylabel('Loan Amount')
plt.title('Relationship between Applicant Income and Loan Amount')
plt.show()

plt.scatter(data = df, x = 'CoapplicantIncome', y = 'LoanAmount');
plt.xlabel('Coapplicant Income')
plt.ylabel('Loan Amount')
plt.title('Relationship between Coapplicant Income and Loan Amount')
plt.show()

base_color = sns.color_palette()[0]
sns.boxplot(data=df, x='Credit_History', y='ApplicantIncome', color=base_color)

plt.xlabel('Credit History')
plt.ylabel('Applicant Income')
plt.title('Relationship between ApplicantIncome and Credit_History')

plt.show()

sns.boxplot(data=df, x='Property_Area', y='LoanAmount', color=base_color)

plt.xlabel('Property Area')
plt.ylabel('Loan Amount')
plt.title('Loan Amount by Property Area')

plt.show()

cross_tab = pd.crosstab(df['Education'], df['Loan_Status'])
print(cross_tab)

sns.heatmap(pd.crosstab(df.Education, df.Loan_Status), annot=True, fmt='d');

cross_tab = pd.crosstab(df['Self_Employed'], df['Loan_Status'])
print(cross_tab)

sns.heatmap(pd.crosstab(df.Self_Employed, df.Loan_Status), annot=True, fmt='d');

numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']

correlation_matrix = df[numerical_columns].corr()

sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

from sklearn import preprocessing

# lable encoders
label_encoder = preprocessing.LabelEncoder()

# converting gender to numeric values
df['Gender'] = label_encoder.fit_transform(df['Gender'])
df['Married'] = label_encoder.fit_transform(df['Married'])
df['Self_Employed'] = label_encoder.fit_transform(df['Self_Employed'])
df['Loan_Status'] = label_encoder.fit_transform(df['Loan_Status'])


# head
df.head()

encoded_df = pd.get_dummies(df['Property_Area'], prefix='Property_Area', prefix_sep='_')
df = pd.concat([df.drop('Property_Area', axis=1), encoded_df], axis=1)

df.head()

df['Education_encoded'] = df['Education'].map({'Graduate': 1, 'Not Graduate':0})


df = df.drop('Education', axis=1)

df.head()

print(df.isnull().sum())

df.dtypes

#df['Dependents'] = df['Dependents'].replace('0.0', '0')  # Replace '0.0' with '0'
df['Dependents'] = df['Dependents'].astype(int)  # Convert the entire column to int type

df.head()

# Separate features and target variable

X = df.drop(['Loan_ID', 'Loan_Status'], axis=1)
y = df['Loan_Status']

#Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model 1
# DecisionTree

#Create and train the Decision Tree classifier
model = DecisionTreeClassifier()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("Predicted labels:", y_pred)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Visualize the Decision Tree
plt.figure(figsize=(15, 10))
plot_tree(model, feature_names=X_train.columns, filled=True)
plt.show()

# Model 2
# Naive Bayes

nb_classifier = GaussianNB()
nb_classifier.fit(X_train, y_train)
y_pred = nb_classifier.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Make predictions on the test set
y_pred = nb_classifier.predict(X_test)

# Print the predicted labels
print("Predicted labels:", y_pred)

# visual

# Model 3
# Gradient Boosting

# Create a Gradient Boosting classifier
gb_classifier = GradientBoostingClassifier()

# Train the model on the training data
gb_classifier.fit(X_train, y_train)

# Use the trained model to make predictions on the test data
y_pred = gb_classifier.predict(X_test)

print("Predicted labels:", y_pred)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# visual

# model 4
# Neural Networks

# Scale the numerical features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the Neural Network architecture
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32)

# Evaluate the model on the testing data
loss, accuracy = model.evaluate(X_test, y_test)
print('Test Loss:', loss)
print('Test Accuracy:', accuracy)

# visual





